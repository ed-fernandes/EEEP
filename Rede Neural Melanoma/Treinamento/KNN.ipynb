{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "import itertools\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NomeBase = 'LBP10r_1_5_p_12'\n",
    "#NomeBase = 'LBP20r_1_5_p_12'\n",
    "#NomeBase = 'LBP30r_1_5_p_12'\n",
    "#NomeBase = 'LBP40r_1_5_p_12'\n",
    "#NomeBase = 'LBP50r_1_5_p_12'\n",
    "#NomeBase = 'LBP75r_1_5_p_12'\n",
    "#NomeBase = 'LBP100r_1_5_p_12'\n",
    "\n",
    "#NomeBase = 'LBP10r_3_p_24'\n",
    "#NomeBase = 'LBP20r_3_p_24'\n",
    "#NomeBase = 'LBP30r_3_p_24'\n",
    "#NomeBase = 'LBP40r_3_p_24'\n",
    "#NomeBase = 'LBP50r_3_p_24'\n",
    "NomeBase = 'GLCMMaior'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "valor = 1\n",
    "base = pd.read_csv('../Datasets/' + str(NomeBase)+'.txt', header=None)\n",
    "entradas = base.iloc[:, 0:len(base.columns) -valor].values \n",
    "\n",
    "classes = base.iloc[:,len(base.columns)-valor].values\n",
    "\n",
    "NumColunas = len(base.columns) - valor\n",
    "caminho = '../resultados/KNN/PesosKNN_Base'+str(NomeBase)\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(base.columns)-valor):\n",
    "    entradas[:,i] = (entradas[:,i] - np.mean(entradas[:,i]))/entradas[:,i].std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(entradas)\n",
    "entradas = scaler.transform(entradas) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entradas_min = entradas.min()\n",
    "entradas_max = entradas.max()\n",
    "entradas_range = (entradas_max - entradas_min)\n",
    "entradas = (entradas - entradas_min)/(entradas_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "classes = labelEncoder.fit_transform(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão da base em treinamento (80%) e teste (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_trei_test(entradas, classes, percentual):\n",
    "    result = []\n",
    "    while (len(result)) != len(entradas):\n",
    "        r = randint(0, len(entradas)-1)\n",
    "        if r not in result:\n",
    "            result.append(r)    \n",
    "\n",
    "    repeticoes = np.zeros(np.max(classes)+1)\n",
    "    \n",
    "    for i in range(len(entradas)):\n",
    "        repeticoes[classes[i]] = repeticoes[classes[i]] + 1\n",
    "    repeticoes = np.array(repeticoes)\n",
    "    minimo = int(np.min(repeticoes) * (1 - percentual))\n",
    "    \n",
    "    treino = int((minimo) * (np.max(classes)+1) )\n",
    "    teste = int(len(entradas) - treino)\n",
    "\n",
    "    entradas_trei = np.zeros((treino, NumColunas))\n",
    "    entradas_test = np.zeros((teste, NumColunas))\n",
    "    classes_trei = np.zeros((treino)) \n",
    "    classes_test = np.zeros((teste))\n",
    "    classeErro_trei = np.zeros((treino))\n",
    "    classeErro_test = np.zeros((teste))\n",
    " \n",
    "    contTreino = 0\n",
    "    contTest = 0\n",
    "    vetorMinimo = np.zeros(np.max(classes)+1)\n",
    "\n",
    "    for i in range(len(classes)):    \n",
    "        if (vetorMinimo[classes[result[i]]] < minimo):            \n",
    "            entradas_trei[contTreino] = entradas[result[i]]\n",
    "            classes_trei[contTreino] = classes[result[i]]\n",
    "          #  classeErro_trei[contTreino] = classesErro[result[i]]\n",
    "            contTreino = contTreino + 1\n",
    "            vetorMinimo[classes[result[i]]] = vetorMinimo[classes[result[i]]] + 1\n",
    "            \n",
    "        else:   \n",
    "            entradas_test[contTest] = entradas[result[i]]            \n",
    "            classes_test[contTest] = classes[result[i]]\n",
    "          #  classeErro_test[contTest] = classesErro[result[i]]\n",
    "            contTest = contTest + 1        \n",
    "\n",
    "\n",
    "    return entradas_trei, entradas_test, classes_trei, classes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "classes = labelEncoder.fit_transform(classes)\n",
    "NumClasses = np.max(classes) + 2\n",
    "\n",
    "entradas_trei, entradas_test, classes_t, classes_te = dividir_trei_test(entradas, classes, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#carregarPesos = int(input(\"Deseja carregar um treinamento? (1 - Sim, 2 - Não) \"))\n",
    "carregarPesos = 2\n",
    "if (carregarPesos != 1):        \n",
    "    kf = KFold(n_splits=10)\n",
    "    vizinhos = int(input(\"Digite a quantidade de vizinhos: \"))\n",
    "    classificador = KNeighborsClassifier(n_neighbors=vizinhos, metric='chebyshev')  \n",
    "      \n",
    " \n",
    "    cross_val_score(classificador, entradas_trei, classes_t, scoring='accuracy', cv=10).mean()\n",
    "\n",
    "if (carregarPesos == 1):\n",
    "    numClass = int(input(\"Digite o número do diretório que deseja carregar\"))\n",
    "    classificador = load(str(caminho)+'/'+str(numClass)+'/classificadorKNN.joblib') \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classificador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador.fit(entradas_trei, classes_t)\n",
    "ACtreino = (classificador.score(entradas_trei, classes_t)) * 100\n",
    "ACTreiE = 100 - ACtreino \n",
    "\n",
    "previsoesTrei = classificador.predict(entradas_trei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matriz de Confusão',\n",
    "                          cmap=plt.cm.Blues):   \n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Saída correta')\n",
    "    plt.xlabel('Saída encontrada')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(classes_t, previsoesTrei)\n",
    "plot_confusion_matrix(cm, \n",
    "                      classes=['0', '1', 'FR'],\n",
    "                      title='Treinamento - KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contT = 0\n",
    "errosTrei = []\n",
    "errosTreiC = []\n",
    "for i in range (len(classes_t)):\n",
    "    if (classes_t[i] != previsoesTrei[i] and previsoesTrei[i] != 2):\n",
    "        contT += 1\n",
    "        errosTrei.append(classes_t[i])\n",
    "        #errosTreiC.append(classeErro_trei[i])\n",
    "        \n",
    "erro = (contT * 100)/len(classes_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ac0 = precision_recall_fscore_support(classes_t,previsoesTrei, average=None)[0][0]\n",
    "Ac1 = precision_recall_fscore_support(classes_t,previsoesTrei, average=None)[0][1]\n",
    "\n",
    "print(\"Acurácia nas peles boas: \" + str(Ac0))\n",
    "print(\"Acurácia nas peles ruins: \" + str(Ac1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = classificador.predict(entradas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (carregarPesos != 1):\n",
    "    import os\n",
    "    if not os.path.exists(str(caminho)+\"/\"):\n",
    "        os.mkdir(str(caminho))      \n",
    "    \n",
    "    valor  = 0\n",
    " \n",
    "\n",
    "    if not os.path.exists(str(caminho)+\"/\"+str(int(valor))):\n",
    "        os.mkdir(str(caminho)+ \"/\" + str(int(valor)))    \n",
    "\n",
    "    else:       \n",
    "        b = os.listdir(caminho)\n",
    "        #print(b)\n",
    "        a = np.zeros(len(b))\n",
    "\n",
    "        for i in range(len(b)):\n",
    "            a[i] = int(b[i])\n",
    "\n",
    "        valor = np.max(a)\n",
    "        valor = valor + 1\n",
    "\n",
    "        os.mkdir(str(caminho) + \"/\"+ str(int(valor)))\n",
    "  \n",
    "    dump(classificador, str(caminho) + '/'+str(int(valor))+'/classificadorKNN.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(classes_te, previsoes)\n",
    "plot_confusion_matrix(cm, \n",
    "                      classes=['0', '1', 'FR'],\n",
    "                      title='Teste - KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "errosTest = []\n",
    "errosTestC = []\n",
    "for i in range (len(classes_te)):\n",
    "    if (classes_te[i] != previsoes[i] and previsoes[i] != 2):\n",
    "        cont += 1\n",
    "        errosTest.append(classes_te[i])\n",
    "       # errosTestC.append(classeErro_test[i])\n",
    "        \n",
    "erro = (cont * 100)/len(classes_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(classes_te,previsoes))  \n",
    "\n",
    "\n",
    "\n",
    "Ac0T = precision_recall_fscore_support(classes_te,previsoes, average=None)[0][0]\n",
    "Ac1T = precision_recall_fscore_support(classes_te,previsoes, average=None)[0][1]\n",
    "\n",
    "print(\"Acurácia nas peles boas: \" + str(Ac0T))\n",
    "print(\"Acurácia nas peles ruins: \" + str(Ac1T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (carregarPesos != 1):  \n",
    "    caminhoTexto = '../resultados/KNN/'+str(NomeBase)+'Dados.txt'\n",
    "    \n",
    "    if not os.path.exists(caminhoTexto):\n",
    "        arquivo = open(caminhoTexto, 'w')\n",
    "        arquivo.writelines(\"vizinhos, Trei0, Trei1, Test0, Test1, erroTrei, erroTest, acertoTrei, acertoTest\")\n",
    "        arquivo.close()\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    arquivo = open(caminhoTexto, 'r')\n",
    "    conteudo = arquivo.readlines()\n",
    "        \n",
    "    conteudo.append(\"\\n\"+ str(vizinhos)+\", \"+ str(Ac0)+\", \"+ str(Ac1)+\", \"+ str(Ac0T)+\", \"+ str(Ac1T)+\", \" + str(ACTreiE)+\", \"+ str(erro)+\", \"+ str(ACtreino)+ \", \" + str(100 - erro))\n",
    "\n",
    "    #### Abre o arquivo como escrita, escreve o conteúdo e fecha o mesmo\n",
    "        \n",
    "    arquivo = open('../resultados/KNN/'+str(NomeBase)+'Dados.txt', 'w')\n",
    "    arquivo.writelines(conteudo)\n",
    "    arquivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('../resultados/KNN/'+str(NomeBase)+'Dados.txt')\n",
    "\n",
    "arquivo = pd.read_csv('../resultados/KNN/'+str(NomeBase)+'Dados.txt')\n",
    "arquivo = arquivo.sort_values(by=[' acertoTest', ' acertoTrei'], ascending=False)\n",
    "print(\"10 Melhores Resultados - Base \"+ str(NomeBase))\n",
    "\n",
    "arquivo.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Treino\")\n",
    "print(\"Quantidade de erros \"+ str(contT))\n",
    "print(\"Total \" + str(len(classes_t)))\n",
    "print(\"Erros Normal e Falha\" )\n",
    "print({x:errosTrei.count(x) for x in set(errosTrei)})\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Teste\")\n",
    "print(\"Quantidade de erros \"+ str(cont))\n",
    "print(\"Total \" + str(len(classes_te)))\n",
    "print(\"Erros Normal e Falha\" )\n",
    "print({x:errosTest.count(x) for x in set(errosTest)})\n",
    "\n",
    "\n",
    "print(\"Treinamento:\")\n",
    "print(\"Percentual de acerto  \"+ str(ACtreino))\n",
    "print(\"Percentual de erro \"+ str(ACTreiE))\n",
    "\n",
    "print(\"Teste:\")\n",
    "print(\"Percentual de acerto  \"+ str(100 - erro))\n",
    "print(\"Percentual de erro \"+ str(erro))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
