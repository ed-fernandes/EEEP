{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "import itertools\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'Solver terminated early.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NomeBase = \"GLCM\"\n",
    "NomeBase = \"GLCMMaior\"\n",
    "\n",
    "valor = 1\n",
    "base = pd.read_csv('../Datasets/' + str(NomeBase)+'.txt')\n",
    "\n",
    "\n",
    "entradas = base.iloc[:, 0:len(base.columns) -valor].values \n",
    "\n",
    "classes = base.iloc[:,len(base.columns)-valor].values\n",
    "\n",
    "NumColunas = len(base.columns) - valor\n",
    "caminho = '../resultados/SVM/PesosSVM_Base'+str(NomeBase)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(base.columns)-valor):\n",
    "    entradas[:,i] = (entradas[:,i] - np.mean(entradas[:,i]))/entradas[:,i].std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range (len(base.columns)-valor):\n",
    "        entradas[:,i] = (entradas[:,i] - np.min(entradas[:,i]))/(np.max(entradas[:,i]) - np.min(entradas[:,i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "classes = labelEncoder.fit_transform(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão da base em treinamento (80%) e teste (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_trei_test(entradas, classes, percentual):\n",
    "    result = []\n",
    "    while (len(result)) != len(entradas):\n",
    "        r = randint(0, len(entradas)-1)\n",
    "        if r not in result:\n",
    "            result.append(r)    \n",
    "\n",
    "    repeticoes = np.zeros(np.max(classes)+1)\n",
    "    \n",
    "    for i in range(len(entradas)):\n",
    "        repeticoes[classes[i]] = repeticoes[classes[i]] + 1\n",
    "    repeticoes = np.array(repeticoes)\n",
    "    minimo = int(np.min(repeticoes) * (1 - percentual))\n",
    "    \n",
    "    treino = int((minimo) * (np.max(classes)+1) )\n",
    "    teste = int(len(entradas) - treino)\n",
    "\n",
    "    entradas_trei = np.zeros((treino, NumColunas))\n",
    "    entradas_test = np.zeros((teste, NumColunas))\n",
    "    classes_trei = np.zeros((treino)) \n",
    "    classes_test = np.zeros((teste))\n",
    "\n",
    " \n",
    "    contTreino = 0\n",
    "    contTest = 0\n",
    "    vetorMinimo = np.zeros(np.max(classes)+1)\n",
    "\n",
    "    for i in range(len(classes)):    \n",
    "        if (vetorMinimo[classes[result[i]]] < minimo):            \n",
    "            entradas_trei[contTreino] = entradas[result[i]]\n",
    "            classes_trei[contTreino] = classes[result[i]]\n",
    "   \n",
    "            contTreino = contTreino + 1\n",
    "            vetorMinimo[classes[result[i]]] = vetorMinimo[classes[result[i]]] + 1\n",
    "            \n",
    "        else:   \n",
    "            entradas_test[contTest] = entradas[result[i]]            \n",
    "            classes_test[contTest] = classes[result[i]]\n",
    "           \n",
    "            contTest = contTest + 1        \n",
    "\n",
    "\n",
    "    return entradas_trei, entradas_test, classes_trei, classes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "classes = labelEncoder.fit_transform(classes)\n",
    "NumClasses = np.max(classes) + 2\n",
    "\n",
    "entradas_trei, entradas_test, classes_t, classes_te = dividir_trei_test(entradas, classes, 0.2)\n",
    "contador = np.zeros((3))\n",
    "\n",
    "classes_test =  np.array(pd.get_dummies(classes_te))\n",
    "classes_trei =  np.array(pd.get_dummies(classes_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels:\n",
    "#### linear, poly, sigmoid e rbf (tem tendências as melhores resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = Parâmetro de penalidade C do termo de erro.\n",
    "\n",
    "Random_state = embaralhar os dados para estimativas de probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregarPesos = int(input(\"Deseja carregar um treinamento? (1 - Sim, 2 - Não) \"))\n",
    "carregarPesos = 2\n",
    "if (carregarPesos != 1):\n",
    "    print(\"Digite: \")\n",
    "    print(\"1: Linear \")\n",
    "    print(\"2: Polinomial \")\n",
    "    print(\"3: RBF \")\n",
    "    print(\"4: Sigmoid \")\n",
    "    TK = int(input(\"\"))\n",
    "    if (TK == 1): \n",
    "        k = \"linear\"\n",
    "    if (TK == 2): \n",
    "        k = \"poly\"\n",
    "    if (TK == 3): \n",
    "        k = \"rbf\"\n",
    "    if (TK == 4): \n",
    "        k = \"sigmoid\"\n",
    "    #RS = int(input(\"Digite o valor do random state: \"))\n",
    "    RS = 1\n",
    "    c = float(input(\"Digite o valor do c: \"))\n",
    "    g = 1\n",
    "    #g = float(input(\"Digite o valor do gamma: \"))\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=10)\n",
    "    \n",
    "    classificador = SVC(kernel= k, random_state = RS, C = c, gamma=\"scale\", tol=0.0001, decision_function_shape='ovo', max_iter=500)\n",
    " \n",
    "    for train_indices, test_indices in kf.split(entradas_trei):\n",
    "        classificador.fit(entradas_trei[train_indices], classes_t[train_indices])\n",
    "        print(classificador.score(entradas_trei[test_indices], classes_t[test_indices]))\n",
    "\n",
    "if (carregarPesos == 1):\n",
    "    numClass = int(input(\"Digite o número do diretório que deseja carregar\"))\n",
    "    classificador = load(str(caminho)+'/'+str(numClass)+'/classificadorSVM.joblib') \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classificador.fit(entradas_trei, classes_t)\n",
    "ACtreino = (classificador.score(entradas_trei, classes_t)) * 100\n",
    "ACTreiE = 100 - ACtreino \n",
    "\n",
    "previsoesTrei = classificador.predict(entradas_trei)\n",
    "print(len(classificador.support_vectors_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matriz de Confusão',\n",
    "                          cmap=plt.cm.Blues):   \n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Saída correta')\n",
    "    plt.xlabel('Saída encontrada')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(classes_t, previsoesTrei)\n",
    "plot_confusion_matrix(cm, \n",
    "                      classes=['0', '1', 'FR'],\n",
    "                      title='Treinamento - SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contT = 0\n",
    "errosTrei = []\n",
    "errosTreiC = []\n",
    "for i in range (len(classes_t)):\n",
    "    if (classes_t[i] != previsoesTrei[i] and previsoesTrei[i] != 2):\n",
    "        contT += 1\n",
    "        errosTrei.append(classes_t[i])\n",
    "  \n",
    "        \n",
    "erro = (contT * 100)/len(classes_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ac0 = precision_recall_fscore_support(classes_t,previsoesTrei, average=None)[0][0]\n",
    "Ac1 = precision_recall_fscore_support(classes_t,previsoesTrei, average=None)[0][1]\n",
    "\n",
    "print(\"Acurácia nas peles boas: \" + str(Ac0))\n",
    "print(\"Acurácia nas peles ruins: \" + str(Ac1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = classificador.predict(entradas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (carregarPesos != 1):\n",
    "    import os\n",
    "    if not os.path.exists(str(caminho)+\"/\"):\n",
    "        os.mkdir(str(caminho))      \n",
    "    \n",
    "    valor  = 0\n",
    " \n",
    "\n",
    "    if not os.path.exists(str(caminho)+\"/\"+str(int(valor))):\n",
    "        os.mkdir(str(caminho)+ \"/\" + str(int(valor)))    \n",
    "\n",
    "    else:       \n",
    "        b = os.listdir(caminho)\n",
    "        #print(b)\n",
    "        a = np.zeros(len(b))\n",
    "\n",
    "        for i in range(len(b)):\n",
    "            a[i] = int(b[i])\n",
    "\n",
    "        valor = np.max(a)\n",
    "        valor = valor + 1\n",
    "\n",
    "        os.mkdir(str(caminho) + \"/\"+ str(int(valor)))\n",
    "  \n",
    "    dump(classificador, str(caminho) + '/'+str(int(valor))+'/classificadorSVM.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(classes_te, previsoes)\n",
    "plot_confusion_matrix(cm, \n",
    "                      classes=['0', '1', 'FR'],\n",
    "                      title='Teste - SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "errosTest = []\n",
    "errosTestC = []\n",
    "for i in range (len(classes_te)):\n",
    "    if (classes_te[i] != previsoes[i] and previsoes[i] != 2):\n",
    "        cont += 1\n",
    "        errosTest.append(classes_te[i])\n",
    "    \n",
    "        \n",
    "erro = (cont * 100)/len(classes_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(classes_te,previsoes))  \n",
    "\n",
    "print(classes_te)\n",
    "\n",
    "\n",
    "Ac0T = precision_recall_fscore_support(classes_te,previsoes, average=None)[0][0]\n",
    "Ac1T = precision_recall_fscore_support(classes_te,previsoes, average=None)[0][1]\n",
    "\n",
    "print(\"Acurácia nas peles boas: \" + str(Ac0T))\n",
    "print(\"Acurácia nas peles ruins: \" + str(Ac1T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (carregarPesos != 1 and TK == 1):    \n",
    "    # Plot data points and color using their class\n",
    "    color = ['black' if c == 0 else 'lightgrey' for c in classes_t]\n",
    "    plt.scatter(entradas_trei[:,0], entradas_trei[:,1], c=color)\n",
    "\n",
    "    # Create the hyperplane\n",
    "    w = classificador.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(-2.5, 2.5)\n",
    "    yy = a * xx - (classificador.intercept_[0]) / w[1]\n",
    "\n",
    "    # Plot the hyperplane\n",
    "    plt.plot(xx, yy)\n",
    "    plt.axis(\"off\"), plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (carregarPesos != 1):  \n",
    "    caminhoTexto = '../resultados/SVM/'+str(NomeBase)+'Dados.txt'\n",
    "    \n",
    "    if not os.path.exists(caminhoTexto):\n",
    "        arquivo = open(caminhoTexto, 'w')\n",
    "        arquivo.writelines(\"kernel, randomState, c, gama, Trei0, Trei1, Test0, Test1, erroTrei, erroTest, acertoTrei, acertoTest, vetores\")\n",
    "        arquivo.close()     \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    arquivo = open(caminhoTexto, 'r')\n",
    "    conteudo = arquivo.readlines()\n",
    "        \n",
    "    conteudo.append(\"\\n\"+str(k)+\", \"+ str(RS)+\", \"+ str(c)+\", \"+ str(g)+\", \"+ str(Ac0)+\", \"+ str(Ac1)+\", \"+ str(Ac0T)+\", \"+ str(Ac1T)+\", \" + str(ACTreiE)+\", \"+ str(erro)+\", \"+ str(ACtreino)+ \", \" + str(100 - erro)+ \", \"+ str(len(classificador.support_vectors_)))\n",
    "\n",
    "    #### Abre o arquivo como escrita, escreve o conteúdo e fecha o mesmo\n",
    "        \n",
    "    arquivo = open('../resultados/SVM/'+str(NomeBase)+'Dados.txt', 'w')\n",
    "    arquivo.writelines(conteudo)\n",
    "    arquivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print('../resultados/SVM/'+str(NomeBase)+'Dados.txt')\n",
    "\n",
    "arquivo = pd.read_csv('../resultados/SVM/'+str(NomeBase)+'Dados.txt')\n",
    "arquivo = arquivo.sort_values(by=[' acertoTest', ' acertoTrei'], ascending=False)\n",
    "print(\"10 Melhores Resultados - Base \"+ str(NomeBase))\n",
    "\n",
    "arquivo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Treino\")\n",
    "print(\"Quantidade de erros \"+ str(contT))\n",
    "print(\"Total \" + str(len(classes_t)))\n",
    "print(\"Erros Normal e Falha\" )\n",
    "print({x:errosTrei.count(x) for x in set(errosTrei)})\n",
    "print(\"Erros por classe\" )\n",
    "print({x:errosTreiC.count(x) for x in set(errosTreiC)})\n",
    "\n",
    "print(\"\")\n",
    "print(\"Teste\")\n",
    "print(\"Quantidade de erros \"+ str(cont))\n",
    "print(\"Total \" + str(len(classes_te)))\n",
    "print(\"Erros Normal e Falha\" )\n",
    "print({x:errosTest.count(x) for x in set(errosTest)})\n",
    "print(\"Erros por classe\" )\n",
    "print({x:errosTestC.count(x) for x in set(errosTestC)})\n",
    "\n",
    "print(\"Treinamento:\")\n",
    "print(\"Percentual de acerto  \"+ str(ACtreino))\n",
    "print(\"Percentual de erro \"+ str(ACTreiE))\n",
    "\n",
    "print(\"Teste:\")\n",
    "print(\"Percentual de acerto  \"+ str(100 - erro))\n",
    "print(\"Percentual de erro \"+ str(erro))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
